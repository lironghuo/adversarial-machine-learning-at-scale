{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minddo/adversarial-machine-learning-at-scale/blob/master/Generate%20adversarial%20example.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2i4-ZsLsTOPp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def FGSM(model, CRITERION ,images, labels, epsilon=None ,train= True):\n",
        "    # Auther suggest that set up the epsilon randomly ~ N(0, 8) (range(0,16)), in test time, use the user defined  valus. \n",
        "    if train==True:\n",
        "        epsilon=abs( torch.normal(torch.tensor([0.0]),torch.tensor([8/256]))).to(\"cuda\")\n",
        "    else:\n",
        "        epsilon=epsilon.to(\"cuda\")\n",
        "    \n",
        "    # as y_target, FGSM use ture label \n",
        "    labels = labels.detach()\n",
        "    images.requires_grad = True\n",
        "    outputs = model(images)\n",
        "    \n",
        "    # gradinet of y_true and output\n",
        "    model.zero_grad()\n",
        "    cost = CRITERION(outputs, labels)\n",
        "    cost.backward()\n",
        "\n",
        "    adv_images = images -  epsilon*images.grad.sign()\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    adv_image = torch.clamp(adv_images, 0, 1)\n",
        "    return adv_images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoqZ9c0PTSL3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_step_target(model, CRITERION ,images , epsilon=None ,train= True):\n",
        "    \n",
        "    # Auther suggest that set up the epsilon randomly ~ N(0, 8) (range(0,16)), in test time, use the user defined  valus. \n",
        "    if train==True:\n",
        "        epsilon=abs( torch.normal(torch.tensor([0.0]),torch.tensor([8/256]))).to(\"cuda\")\n",
        "    else:\n",
        "        epsilon=epsilon.to(\"cuda\")\n",
        "    \n",
        "    # as y_target, step l.l use y_LL (least likely class)\n",
        "    outputs = model(images)\n",
        "    _, labels = torch.min(outputs.data, 1)\n",
        "    labels = labels.detach_()\n",
        "    \n",
        "    images.requires_grad = True\n",
        "    outputs = model(images)\n",
        "    \n",
        "    \n",
        "    # gradinet of y_LL and output\n",
        "    model.zero_grad()\n",
        "    cost = CRITERION(outputs, labels)\n",
        "    cost.backward()\n",
        "\n",
        "    adv_images = images -  epsilon*images.grad.sign()\n",
        "    # Adding clipping to maintain [0,1] range\n",
        "    adv_image = torch.clamp(adv_images, 0, 1)\n",
        "    return adv_images\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PTUcKLtuTWiV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def basic_iterative(model, CRITERION, images, labels, scale, alpha=1, iters=0, eps=None, train= True) :\n",
        "    \n",
        "    images = images.to(\"cuda\")    \n",
        "    outputs = model(images)\n",
        "    _, labels = torch.min(outputs.data, 1)\n",
        "    labels = labels.detach_()\n",
        "        \n",
        "    clamp_max = 255\n",
        "    \n",
        "     # Auther suggest that set up the epsilon randomly ~ N(0, 8) (range(0,16)), in test time, use the user defined  valus.\n",
        "    if train ==True:\n",
        "        eps= abs(np.random.normal(0, 8, 1)[0])\n",
        "    else:\n",
        "        eps=eps\n",
        "        \n",
        "    if iters == 0 :\n",
        "    # The paper said min(eps + 4, 1.25*eps) is used as iterations\n",
        "        iters = int(min(eps + 4, 1.25*eps))\n",
        "        \n",
        "    if scale :\n",
        "        eps = eps / 255\n",
        "        clamp_max = clamp_max / 255\n",
        "\n",
        "    for i in range(iters) :    \n",
        "        images.requires_grad = True\n",
        "        outputs = model(images)\n",
        "\n",
        "        model.zero_grad()\n",
        "        cost = CRITERION(outputs, labels).to(\"cuda\")\n",
        "        cost.backward()\n",
        "\n",
        "        attack_images = images + alpha*images.grad.sign()\n",
        "        \n",
        "        # Clip attack images(X')\n",
        "        # min{255, X+eps, max{0, X-eps, X'}}\n",
        "        # = min{255, min{X+eps, max{max{0, X-eps}, X'}}}\n",
        "        \n",
        "        # a = max{0, X-eps}\n",
        "        a = torch.clamp(images - eps, min=0)\n",
        "        # b = max{a, X'}\n",
        "        b = (attack_images>=a).float()*attack_images + (a>attack_images).float()*a\n",
        "        # c = min{X+eps, b}\n",
        "        c = (b > images+eps).float()*(images+eps) + (images+eps >= b).float()*b\n",
        "        # d = min{255, c}\n",
        "        images = torch.clamp(c, max=clamp_max).detach_()\n",
        "            \n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XKDo-ZATYp2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def iterative_least_likely_class(model, CRITERION, images, scale, alpha=1, iters=0, eps=None, train= True) :\n",
        "    \n",
        "    images = images.to(\"cuda\")    \n",
        "    outputs = model(images)\n",
        "    _, labels = torch.min(outputs.data, 1)\n",
        "    labels = labels.detach_()\n",
        "        \n",
        "    clamp_max = 255\n",
        "    \n",
        "     # Auther suggest that set up the epsilon randomly ~ N(0, 8) (range(0,16)), in test time, use the user defined  valus.\n",
        "    if train ==True:\n",
        "        eps= abs(np.random.normal(0, 8, 1)[0])\n",
        "    else:\n",
        "        eps=eps\n",
        "        \n",
        "        \n",
        "    if iters == 0 :\n",
        "    # The paper said min(eps + 4, 1.25*eps) is used as iterations\n",
        "        iters = int(min(eps + 4, 1.25*eps))\n",
        "        \n",
        "    if scale :\n",
        "        eps = eps / 255\n",
        "        clamp_max = clamp_max / 255\n",
        "        \n",
        "    for i in range(iters) :    \n",
        "        images.requires_grad = True\n",
        "        outputs = model(images)\n",
        "\n",
        "        model.zero_grad()\n",
        "        cost = CRITERION(outputs, labels).to(\"cuda\")\n",
        "        cost.backward()\n",
        "\n",
        "        attack_images = images - alpha*images.grad.sign()\n",
        "        \n",
        "        # Clip attack images(X')\n",
        "        # min{255, X+eps, max{0, X-eps, X'}}\n",
        "        # = min{255, min{X+eps, max{max{0, X-eps}, X'}}}\n",
        "        \n",
        "        # a = max{0, X-eps}\n",
        "        a = torch.clamp(images - eps, min=0)\n",
        "        # b = max{a, X'}\n",
        "        b = (attack_images>=a).float()*attack_images + (a>attack_images).float()*a\n",
        "        # c = min{X+eps, b}\n",
        "        c = (b > images+eps).float()*(images+eps) + (images+eps >= b).float()*b\n",
        "        # d = min{255, c}\n",
        "        images = torch.clamp(c, max=clamp_max).detach_()\n",
        "    \n",
        "    return images"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}